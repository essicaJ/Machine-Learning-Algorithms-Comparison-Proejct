{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.21.2.\n"
     ]
    }
   ],
   "source": [
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, urls):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    for url in urls:\n",
    "        data = requests.get(url).content\n",
    "        filename = os.path.join(path, os.path.basename(url))\n",
    "        with open(filename, \"wb\") as file:\n",
    "            file.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adult Dataset Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\",\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"]\n",
    "load_dataset('data', urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"age\", \"workClass\", \"fnlwgt\", \"education\", \"education_num\",\"maritalstatus\", \"occupation\", \"relationship\",\n",
    "          \"race\", \"sex\", \"capitalgain\", \"capitalloss\", \"hours_per_week\", \"native_country\", \"income\"]\n",
    "train_data = pd.read_csv('data/adult.data', names=columns, sep=' *, *', na_values='?', engine='python')\n",
    "test_data = pd.read_csv('data/adult.test', names=columns, sep=' *, *',na_values='?', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "age               32561 non-null int64\n",
      "workClass         30725 non-null object\n",
      "fnlwgt            32561 non-null int64\n",
      "education         32561 non-null object\n",
      "education_num     32561 non-null int64\n",
      "maritalstatus     32561 non-null object\n",
      "occupation        30718 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "sex               32561 non-null object\n",
      "capitalgain       32561 non-null int64\n",
      "capitalloss       32561 non-null int64\n",
      "hours_per_week    32561 non-null int64\n",
      "native_country    31978 non-null object\n",
      "income            32561 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16282 entries, 0 to 16281\n",
      "Data columns (total 15 columns):\n",
      "age               16282 non-null object\n",
      "workClass         15318 non-null object\n",
      "fnlwgt            16281 non-null float64\n",
      "education         16281 non-null object\n",
      "education_num     16281 non-null float64\n",
      "maritalstatus     16281 non-null object\n",
      "occupation        15315 non-null object\n",
      "relationship      16281 non-null object\n",
      "race              16281 non-null object\n",
      "sex               16281 non-null object\n",
      "capitalgain       16281 non-null float64\n",
      "capitalloss       16281 non-null float64\n",
      "hours_per_week    16281 non-null float64\n",
      "native_country    16007 non-null object\n",
      "income            16281 non-null object\n",
      "dtypes: float64(5), object(10)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = test_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['fnlwgt','education'], axis=1)\n",
    "test_data = test_data.drop(['fnlwgt', 'education'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one-hot encoding \n",
    "numerical_subset_train = train_data.select_dtypes('number')\n",
    "categorical_subset_train = train_data.select_dtypes('object')\n",
    "categorical_subset_train = categorical_subset_train.drop(['income'], axis=1)\n",
    "categorical_subset_train = pd.get_dummies(categorical_subset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I found out that train and test set have different columns after one-hot encoding, and this is becasue the country 'Holand-Netherlands' does not exist in test data\n",
    "# for convinience drop this row in train\n",
    "categorical_subset_train = categorical_subset_train.drop(['native_country_Holand-Netherlands'],axis=1)\n",
    "train = pd.concat([numerical_subset_train, categorical_subset_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['age'] = test_data['age'].astype(float)\n",
    "numerical_subset_test = test_data.select_dtypes('number')\n",
    "categorical_subset_test = test_data.select_dtypes('object')\n",
    "categorical_subset_test = categorical_subset_test.drop(['income'], axis=1)\n",
    "categorical_subset_test = pd.get_dummies(categorical_subset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([numerical_subset_test, categorical_subset_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_train = train_data['income'].replace({\"<=50K\": 0, \">50K\": 1})\n",
    "income_test = test_data['income'].replace({\"<=50K.\": 0, \">50K.\": 1})\n",
    "Y_adult = pd.concat([income_train, income_test], axis =0)\n",
    "#Y = Y.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.752156\n",
       "1    0.247844\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check data balance\n",
    "pd.Series(Y_adult).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scale train data, only the numerical ones\n",
    "train_fit = StandardScaler().fit(numerical_subset_train)\n",
    "train_sc = train_fit.transform(numerical_subset_train)\n",
    "## scale test data\n",
    "test_fit = StandardScaler().fit(numerical_subset_test)\n",
    "test_sc = test_fit.transform(numerical_subset_test)\n",
    "## combine, get X\n",
    "X_adult_train= np.hstack((train_sc, categorical_subset_train))\n",
    "X_adult_test= np.hstack((test_sc, categorical_subset_test))\n",
    "X_adult = np.vstack((X_adult_train, X_adult_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##def logistic_classifier (train_X, train_Y, test_X, test_Y):\n",
    "    #C = [10**-8, 10**-7, 10**-6, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 10**1, 10**2, 10**3, 10**4, 0]\n",
    "    #grid={\"C\":C, \"penalty\":[\"l1\",\"l2\"]}\n",
    "    #scoring = ['accuracy', 'roc_auc', 'f1']\n",
    "    #classifier = GridSearchCV(LogisticRegression(solver = 'liblinear'), C, cv=5, scoring = scoring, n_jobs=-1)\n",
    "    #classifier.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45222,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_adult.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covertype Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "covtype = pd.read_csv('Downloads\\covtype.csv', sep=' *, *', na_values='?', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.9647\n",
       "1    0.0353\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Turn Y into binary, calculate class distribution\n",
    "index7 = covtype['Cover_Type'] == 7\n",
    "Y_cov = np.where(index7, 1, 0)\n",
    "pd.Series(Y_cov).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cov = covtype.drop(['Cover_Type'], axis=1)\n",
    "fit_cov = StandardScaler().fit(X_cov)\n",
    "X_cov = fit_cov.transform(X_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letter O Positive Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter = pd.read_csv('Downloads\\letter-recognition.csv', sep=' *, *', na_values='?', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.96235\n",
       "1.0    0.03765\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Turn Y into binary, calculate class distribution\n",
    "letterO_Y = np.zeros(len(letter))\n",
    "for i in range(len(letter)):\n",
    "    if letter['letter'][i] == 'O':\n",
    "        letterO_Y[i] += 1\n",
    "    else:\n",
    "        letterO_Y[i] += 0\n",
    "        \n",
    "pd.Series(letterO_Y).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define Y and X, standaridize \n",
    "Y_letterO = letterO_Y\n",
    "X_letterO = letter.drop(['letter'], axis=1)\n",
    "fit_lo = StandardScaler().fit(X_letterO)\n",
    "X_letterO = fit_lo.transform(X_letterO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letter AM Positive Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.503\n",
       "1.0    0.497\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AM = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
    "letterO_AM = np.zeros(len(letter))\n",
    "for i in range(len(letter)):\n",
    "    if letter['letter'][i] in AM:\n",
    "        letterO_AM[i] +=1\n",
    "    else:\n",
    "        letterO_AM += 0\n",
    "        \n",
    "pd.Series(letterO_AM).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_letterAM = letterO_AM\n",
    "X_letterAM = letter.drop(['letter'], axis=1)\n",
    "fit_AM = StandardScaler().fit(X_letterAM)\n",
    "X_letterAM = fit_AM.transform(X_letterAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression for Adult\n",
    "def logistic_classifier(X, Y):\n",
    "    \n",
    "    mean_test_acc = []\n",
    "    \n",
    "    opt_train_acc = []\n",
    "    opt_train_f1= []\n",
    "    opt_train_auc = []\n",
    "    \n",
    "    opt_test_acc = []\n",
    "    opt_test_f1= []\n",
    "    opt_test_auc = []\n",
    "    \n",
    "    for trial in range(5):\n",
    "    \n",
    "        # define parameters\n",
    "        C = [10**-8, 10**-7, 10**-6, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 10**1, 10**2, 10**3, 10**4]\n",
    "        grid={\"C\":C, \"penalty\":[\"l1\",\"l2\"]}\n",
    "        scoring = ['accuracy', 'roc_auc', 'f1']\n",
    "    \n",
    "        # pick random samples\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=len(X)-5000, train_size=5000, random_state=trial, shuffle=True)\n",
    "\n",
    "        # define classifier, fit train Run Gridsearch\n",
    "        classifier = GridSearchCV(LogisticRegression(solver = 'liblinear',class_weight = 'balanced'), grid, cv=5, scoring = scoring, refit = False, n_jobs= -1)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "    \n",
    "        # store best parameters for each metric for training and get accuracy score\n",
    "        best = []\n",
    "        best_index = np.argmin(classifier.cv_results_['rank_test_accuracy'])\n",
    "        best_param = classifier.cv_results_['params'][best_index]\n",
    "        best.append(best_param)\n",
    "    \n",
    "        best_index = np.argmin(classifier.cv_results_['rank_test_roc_auc'])\n",
    "        best_param = classifier.cv_results_['params'][best_index]\n",
    "        best.append(best_param)\n",
    "    \n",
    "        best_index = np.argmin(classifier.cv_results_['rank_test_f1'])\n",
    "        best_param = classifier.cv_results_['params'][best_index]\n",
    "        best.append(best_param)\n",
    "    \n",
    "        mean_test = classifier.cv_results_['mean_test_accuracy']\n",
    "        mean_test_acc.append(mean_test)\n",
    "    \n",
    "        # train samples using each best metric\n",
    "        model1 = LogisticRegression(C=best[0]['C'], penalty=best[0]['penalty'], solver='liblinear',class_weight = 'balanced')\n",
    "        model1.fit(X_train, Y_train)\n",
    "    \n",
    "        model2 = LogisticRegression(C=best[1]['C'], penalty=best[1]['penalty'], solver='liblinear',class_weight = 'balanced')\n",
    "        model2.fit(X_train, Y_train)\n",
    "    \n",
    "        model3 = LogisticRegression(C=best[2]['C'], penalty=best[2]['penalty'], solver='liblinear',class_weight = 'balanced')\n",
    "        model3.fit(X_train, Y_train)\n",
    "        \n",
    "        # get score for train set\n",
    "        acc_train = []\n",
    "        for i in model1, model2, model3:\n",
    "            acc_train.append(accuracy_score(Y_train, i.predict(X_train)))\n",
    "        opt_train_acc.extend(acc_train)\n",
    "    \n",
    "        f1_train = []\n",
    "        for i in model1, model2, model3:\n",
    "            f1_train.append(f1_score(Y_train, i.predict(X_train)))\n",
    "        opt_train_f1.extend(f1_train)\n",
    "\n",
    "        auc_train = []\n",
    "        for i in model1, model2, model3:\n",
    "            auc_train.append(roc_auc_score(Y_train, i.predict(X_train)))\n",
    "        opt_train_auc.extend(auc_train)\n",
    "        \n",
    "        \n",
    "        # get score for test set\n",
    "        acc_test = []\n",
    "        for i in model1, model2, model3:\n",
    "            acc_test.append(accuracy_score(Y_test, i.predict(X_test)))\n",
    "        opt_test_acc.extend(acc_test)\n",
    "    \n",
    "        f1_test = []\n",
    "        for i in model1, model2, model3:\n",
    "            f1_test.append(f1_score(Y_test, i.predict(X_test)))\n",
    "        opt_test_f1.extend(f1_test)\n",
    "\n",
    "        auc_test = []\n",
    "        for i in model1, model2, model3:\n",
    "            auc_test.append(roc_auc_score(Y_test, i.predict(X_test)))\n",
    "        opt_test_auc.extend(auc_test)\n",
    "    \n",
    "    return best, mean_test_acc, opt_train_acc, opt_train_f1, opt_train_auc, opt_test_acc, opt_test_f1, opt_test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM\n",
    "def svm_classifier(X, Y):\n",
    "    \n",
    "    mean_test_acc = []\n",
    "    \n",
    "    opt_train_acc = []\n",
    "    opt_train_f1= []\n",
    "    opt_train_auc = []\n",
    "    \n",
    "    opt_test_acc = []\n",
    "    opt_test_f1= []\n",
    "    opt_test_auc = []\n",
    "\n",
    "    for trial in range(5):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=len(X)-5000, train_size=5000, random_state=trial, shuffle=True)\n",
    "        svm_param = [{'kernel': ['rbf'], 'gamma': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1,2], 'C': [10**-7, 10**-6, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 10**1, 10**2, 10**3, 10**4]},\n",
    "                {'kernel': ['linear'], 'C': [10**-7, 10**-6, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 10**1, 10**2, 10**3, 10**4]},\n",
    "                {'kernel': ['poly'], 'degree': [2, 3], 'C': [10**-7, 10**-6, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 10**1, 10**2, 10**3, 10**4]}]\n",
    "        scoring = ['accuracy', 'roc_auc', 'f1']\n",
    "        svm_classifier = GridSearchCV(svm.SVC(class_weight = 'balanced'), svm_param, cv=5, scoring = scoring, refit = False, n_jobs=-1)\n",
    "        svm_classifier.fit(X_train, Y_train)\n",
    "    \n",
    "        ## store best parameters for each metric\n",
    "        best = []\n",
    "        best_index = np.argmin(svm_classifier.cv_results_['rank_test_accuracy'])\n",
    "        best_param = svm_classifier.cv_results_['params'][best_index]\n",
    "        best.append(best_param)\n",
    "    \n",
    "        best_index = np.argmin(svm_classifier.cv_results_['rank_test_roc_auc'])\n",
    "        best_param = svm_classifier.cv_results_['params'][best_index]\n",
    "        best.append(best_param)\n",
    "    \n",
    "        best_index = np.argmin(svm_classifier.cv_results_['rank_test_f1'])\n",
    "        best_param = svm_classifier.cv_results_['params'][best_index]\n",
    "        best.append(best_param)\n",
    "        \n",
    "        mean_test = svm_classifier.cv_results_['mean_test_accuracy']\n",
    "        mean_test_acc.append(mean_test)\n",
    "        \n",
    "        ## train samples using each best metric\n",
    "        params_svm1=best[0]\n",
    "        model1 = svm.SVC(class_weight='balanced').set_params(**params_svm1)\n",
    "        model1.fit(X_train, Y_train)\n",
    "    \n",
    "        params_svm2=best[1]\n",
    "        model2 = svm.SVC(class_weight='balanced').set_params(**params_svm2)\n",
    "        model2.fit(X_train, Y_train)\n",
    "    \n",
    "        params_svm3=best[2]\n",
    "        model3 = svm.SVC(class_weight='balanced').set_params(**params_svm3)\n",
    "        model3.fit(X_train, Y_train)\n",
    "        \n",
    "        # get score for train set\n",
    "        acc_train = []\n",
    "        for i in model1, model2, model3:\n",
    "            acc_train.append(accuracy_score(Y_train, i.predict(X_train)))\n",
    "        opt_train_acc.extend(acc_train)\n",
    "    \n",
    "        f1_train = []\n",
    "        for i in model1, model2, model3:\n",
    "            f1_train.append(f1_score(Y_train, i.predict(X_train)))\n",
    "        opt_train_f1.extend(f1_train)\n",
    "\n",
    "        auc_train = []\n",
    "        for i in model1, model2, model3:\n",
    "            auc_train.append(roc_auc_score(Y_train, i.predict(X_train)))\n",
    "        opt_train_auc.extend(auc_train)\n",
    "        \n",
    "        ## get score for test set\n",
    "        acc_test = []\n",
    "        for i in model1, model2, model3:\n",
    "            acc_test.append(accuracy_score(Y_test, i.predict(X_test)))\n",
    "        opt_test_acc.extend(acc_test)\n",
    "    \n",
    "        f1_test = []\n",
    "        for i in model1, model2, model3:\n",
    "            f1_test.append(f1_score(Y_test, i.predict(X_test)))\n",
    "        opt_test_f1.extend(f1_test)\n",
    "\n",
    "        auc_test = []\n",
    "        for i in model1, model2, model3:\n",
    "            auc_test.append(roc_auc_score(Y_test, i.predict(X_test)))\n",
    "        opt_test_auc.extend(auc_test)\n",
    "    \n",
    "    return best, mean_test_acc, opt_train_acc, opt_train_f1, opt_train_auc, opt_test_acc, opt_test_f1, opt_test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_classifier(X, Y):\n",
    "    \n",
    "    mean_test_acc = []\n",
    "    \n",
    "    opt_train_acc = []\n",
    "    opt_train_f1= []\n",
    "    opt_train_auc = []\n",
    "    \n",
    "    opt_test_acc = []\n",
    "    opt_test_f1= []\n",
    "    opt_test_auc = []\n",
    "    \n",
    "    for trial in range(5):\n",
    "    \n",
    "        # define parameters\n",
    "        trees= [1024]\n",
    "        max_features = [1,2,4,6,8,12,16, 20]\n",
    "        grid = {'n_estimators': trees, 'max_features': max_features}\n",
    "        scoring = ['accuracy', 'roc_auc', 'f1']\n",
    "                    \n",
    "        # pick random samples\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=len(X)-5000, train_size=5000, random_state=trial, shuffle=True)\n",
    "\n",
    "        # define classifier, fit train Run Gridsearch\n",
    "        classifier = GridSearchCV(RandomForestClassifier(class_weight = 'balanced'), grid, cv=5, scoring = scoring, refit = False, n_jobs=-1)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        \n",
    "        # store best parameters for each metric for training and get accuracy score\n",
    "        best = []\n",
    "        best_index = np.argmin(classifier.cv_results_['rank_test_accuracy'])\n",
    "        best_param = classifier.cv_results_['params'][best_index]\n",
    "        best.append(best_param)\n",
    "    \n",
    "        best_index = np.argmin(classifier.cv_results_['rank_test_roc_auc'])\n",
    "        best_param = classifier.cv_results_['params'][best_index]\n",
    "        best.append(best_param)\n",
    "    \n",
    "        best_index = np.argmin(classifier.cv_results_['rank_test_f1'])\n",
    "        best_param = classifier.cv_results_['params'][best_index]\n",
    "        best.append(best_param)\n",
    "    \n",
    "        mean_test = classifier.cv_results_['mean_test_accuracy']\n",
    "        mean_test_acc.append(mean_test)\n",
    "    \n",
    "        # train samples using each best metric\n",
    "        model1 = RandomForestClassifier(max_features =best[0]['max_features'], class_weight='balanced')\n",
    "        model1.fit(X_train, Y_train)\n",
    "    \n",
    "        model2 = RandomForestClassifier(max_features =best[1]['max_features'], class_weight = 'balanced')\n",
    "        model2.fit(X_train, Y_train)\n",
    "    \n",
    "        model3 = RandomForestClassifier(max_features =best[2]['max_features'], class_weight = 'balanced')\n",
    "        model3.fit(X_train, Y_train)\n",
    "        \n",
    "        # get score for train set\n",
    "        acc_train = []\n",
    "        for i in model1, model2, model3:\n",
    "            acc_train.append(accuracy_score(Y_train, i.predict(X_train)))\n",
    "        opt_train_acc.extend(acc_train)\n",
    "\n",
    "        auc_train = []\n",
    "        for i in model1, model2, model3:\n",
    "            auc_train.append(roc_auc_score(Y_train, i.predict(X_train)))\n",
    "        opt_train_auc.extend(auc_train)\n",
    "        \n",
    "        f1_train = []\n",
    "        for i in model1, model2, model3:\n",
    "            f1_train.append(f1_score(Y_train, i.predict(X_train)))\n",
    "        opt_train_f1.extend(f1_train)\n",
    "        \n",
    "        # get score for test set\n",
    "        acc_test = []\n",
    "        for i in model1, model2, model3:\n",
    "            acc_test.append(accuracy_score(Y_test, i.predict(X_test)))\n",
    "        opt_test_acc.extend(acc_test)\n",
    "    \n",
    "        f1_test = []\n",
    "        for i in model1, model2, model3:\n",
    "            f1_test.append(f1_score(Y_test, i.predict(X_test))) \n",
    "        opt_test_f1.extend(f1_test)\n",
    "\n",
    "        auc_test = []\n",
    "        for i in model1, model2, model3:\n",
    "            auc_test.append(roc_auc_score(Y_test, i.predict(X_test)))\n",
    "        opt_test_auc.extend(auc_test)\n",
    "    \n",
    "    return best, mean_test_acc, opt_train_acc, opt_train_f1, opt_train_auc, opt_test_acc, opt_test_f1, opt_test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_classifier_forletter(X, Y):\n",
    "    \n",
    "    mean_test_acc = []\n",
    "    \n",
    "    opt_train_acc = []\n",
    "    opt_train_f1= []\n",
    "    opt_train_auc = []\n",
    "    \n",
    "    opt_test_acc = []\n",
    "    opt_test_f1= []\n",
    "    opt_test_auc = []\n",
    "    \n",
    "    for trial in range(5):\n",
    "    \n",
    "        # define parameters\n",
    "        trees= [1024]\n",
    "        max_features = [1,2,4,6,8,12,16]\n",
    "        grid = {'n_estimators': trees, 'max_features': max_features}\n",
    "        scoring = ['accuracy', 'roc_auc', 'f1']\n",
    "                    \n",
    "        # pick random samples\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=len(X)-5000, train_size=5000, random_state=trial, shuffle=True)\n",
    "\n",
    "        # define classifier, fit train Run Gridsearch\n",
    "        classifier = GridSearchCV(RandomForestClassifier(class_weight = 'balanced'), grid, cv=5, scoring = scoring, refit = False, n_jobs=-1)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        \n",
    "        # store best parameters for each metric for training and get accuracy score\n",
    "        best = []\n",
    "        best_index = np.argmin(classifier.cv_results_['rank_test_accuracy'])\n",
    "        best_param = classifier.cv_results_['params'][best_index]\n",
    "        best.append(best_param)\n",
    "    \n",
    "        best_index = np.argmin(classifier.cv_results_['rank_test_roc_auc'])\n",
    "        best_param = classifier.cv_results_['params'][best_index]\n",
    "        best.append(best_param)\n",
    "    \n",
    "        best_index = np.argmin(classifier.cv_results_['rank_test_f1'])\n",
    "        best_param = classifier.cv_results_['params'][best_index]\n",
    "        best.append(best_param)\n",
    "    \n",
    "        mean_test = classifier.cv_results_['mean_test_accuracy']\n",
    "        mean_test_acc.append(mean_test)\n",
    "    \n",
    "        # train samples using each best metric\n",
    "        model1 = RandomForestClassifier(max_features =best[0]['max_features'], class_weight='balanced')\n",
    "        model1.fit(X_train, Y_train)\n",
    "    \n",
    "        model2 = RandomForestClassifier(max_features =best[1]['max_features'], class_weight = 'balanced')\n",
    "        model2.fit(X_train, Y_train)\n",
    "    \n",
    "        model3 = RandomForestClassifier(max_features =best[2]['max_features'], class_weight = 'balanced')\n",
    "        model3.fit(X_train, Y_train)\n",
    "        \n",
    "        # get score for train set\n",
    "        acc_train = []\n",
    "        for i in model1, model2, model3:\n",
    "            acc_train.append(accuracy_score(Y_train, i.predict(X_train)))\n",
    "        opt_train_acc.extend(acc_train)\n",
    "\n",
    "        auc_train = []\n",
    "        for i in model1, model2, model3:\n",
    "            auc_train.append(roc_auc_score(Y_train, i.predict(X_train)))\n",
    "        opt_train_auc.extend(auc_train)\n",
    "        \n",
    "        f1_train = []\n",
    "        for i in model1, model2, model3:\n",
    "            f1_train.append(f1_score(Y_train, i.predict(X_train)))\n",
    "        opt_train_f1.extend(f1_train)\n",
    "        \n",
    "        # get score for test set\n",
    "        acc_test = []\n",
    "        for i in model1, model2, model3:\n",
    "            acc_test.append(accuracy_score(Y_test, i.predict(X_test)))\n",
    "        opt_test_acc.extend(acc_test)\n",
    "    \n",
    "        f1_test = []\n",
    "        for i in model1, model2, model3:\n",
    "            f1_test.append(f1_score(Y_test, i.predict(X_test))) \n",
    "        opt_test_f1.extend(f1_test)\n",
    "\n",
    "        auc_test = []\n",
    "        for i in model1, model2, model3:\n",
    "            auc_test.append(roc_auc_score(Y_test, i.predict(X_test)))\n",
    "        opt_test_auc.extend(auc_test)\n",
    "    \n",
    "    return best, mean_test_acc, opt_train_acc, opt_train_f1, opt_train_auc, opt_test_acc, opt_test_f1, opt_test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_letterO.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 59.811641693115234\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "adult_logi = logistic_classifier(X_adult, Y_adult)\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 20453.943395376205\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "adult_svm = svm_classifier(X_adult, Y_adult)\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 474.0063316822052\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "adult_rf = RF_classifier(X_adult, Y_adult)\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 1500.794606924057\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cov_logi = logistic_classifier(X_cov, Y_cov)\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 9453.8247320652\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cov_svm = svm_classifier(X_cov, Y_cov)\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 355.7090907096863\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cov_rf = RF_classifier(X_cov, Y_cov)\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 6.596489191055298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "letterO_logi = logistic_classifier(X_letterO, Y_letterO)\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 21463.724128246307\n"
     ]
    }
   ],
   "source": [
    "start =time.time()\n",
    "letterO_svm = svm_classifier(X_letterO, Y_letterO)\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 268.1994228363037\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "letterO_rf = RF_classifier_forletter(X_letterO, Y_letterO)\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 6.788654565811157\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "letterAM_logi = logistic_classifier(X_letterAM, Y_letterAM)\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 26007.7803709507\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "letterAM_svm = svm_classifier(X_letterAM, Y_letterAM)\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jessica\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 457.0757746696472\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "letterAM_rf = RF_classifier_forletter(X_letterAM, Y_letterAM)\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
